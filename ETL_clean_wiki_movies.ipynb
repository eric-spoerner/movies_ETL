{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# create printouts/logs of record processing.  muck with logger framework\n",
    "    # Make sure to do error logging.\n",
    "# Change column replacement framework to a lookup in a saved CSV.  Current framework is kludgy.\n",
    "    # Convert to lambda function\n",
    "# Declare form_one, form_two in namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Add the clean movie function that takes in the argument, \"movie\".\n",
    "def clean_movie(movie):\n",
    "    \"\"\"\n",
    "    Takes a single wikipedia record, extracts all known values for alternate titles,\n",
    "    and moves them to a list.  Additionally maps redundant/duplicative column names.\n",
    "    \"\"\"\n",
    "    movie = dict(movie) # creates a non-destructive copy.  DON'T UNDERSTAND THIS SYNTAX\n",
    "    \n",
    "    # Clean alternate titles\n",
    "    alt_titles = dict()\n",
    "    languages = ['Arabic',\n",
    "                 'Cantonese',\n",
    "                 'Chinese',\n",
    "                 'French',\n",
    "                 'Hangul',\n",
    "                 'Hebrew',\n",
    "                 'Hepburn',\n",
    "                 'Japanese',\n",
    "                 'Literally',\n",
    "                 'Mandarin',\n",
    "                 'McCune–Reischauer',\n",
    "                 'Polish',\n",
    "                 'Revised Romanization',\n",
    "                 'Romanized',\n",
    "                 'Russian',\n",
    "                 'Simplified',\n",
    "                 'Traditional',\n",
    "                 'Yiddish']\n",
    "\n",
    "    for language in languages:\n",
    "        if language in movie:\n",
    "            alt_titles[language] = movie[language]\n",
    "            movie.pop(language)\n",
    "\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "    \n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "    \n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director(s)')\n",
    "    change_column_name('Director', 'Director(s)')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    \n",
    "    return movie\n",
    "\n",
    "def parse_dollars(s):\n",
    "    \"\"\"\n",
    "    Given string s, parse currency strings to float.\n",
    "    \"\"\"\n",
    "    if type(s) != str:\n",
    "        return np.nan\n",
    "    \n",
    "    # form one: r\"\\$\\s*\\d{1,3}\\.?\\d*\\s*[mb]illi?on\"\n",
    "    # form two: r\"\\$\\s*\\d+[,\\.]\\d{3}\"\n",
    "    \n",
    "    # form: \"$###.# billion: \n",
    "    # remove dollar signs, whitespace, and text.  \n",
    "    # Multiply by 1billion\n",
    "    if re.match(r\"\\$\\s*\\d{1,3}\\.?\\d*\\s*billi?on\", s, flags=re.IGNORECASE):\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]', '', s)\n",
    "        value = float(s) * 10**9\n",
    "        return value\n",
    "     \n",
    "    # form: \"$###.# million: \n",
    "    # remove dollar signs, whitespace, and text.  \n",
    "    # Multiply by 1million   \n",
    "    if re.match(r\"\\$\\s*\\d{1,3}\\.?\\d*\\s*milli?on\", s, flags=re.IGNORECASE):\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]', '', s)\n",
    "        value = float(s) * 10**6\n",
    "        return value    \n",
    "    \n",
    "    # form: $###,###,###\n",
    "    # strip dollar signs and thousands separators\n",
    "    if re.match(r\"\\$\\s*\\d+[,\\.]\\d{3}\", s, flags=re.IGNORECASE):\n",
    "        s = re.sub('\\$|,|\\.','',s)\n",
    "        value = float(s)\n",
    "        return value\n",
    "        \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 2 Add the function that takes in three arguments;\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\n",
    "def import_source_files(wiki_file: str,\n",
    "                        kaggle_file: str,\n",
    "                        ratings_file: str):\n",
    "    \"\"\"\n",
    "    Function takes three arguments, each corresponding to the name\n",
    "    of a specific source csv or json file for the three types of data \n",
    "    objects we are importing.  Returns all three objects as unique\n",
    "    pandas DataFrames.\n",
    "    \"\"\"\n",
    "    # 2. Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    kaggle_metadata = pd.read_csv(kaggle_file, low_memory=False)\n",
    "    ratings = pd.read_csv(ratings_file)\n",
    "\n",
    "    # 3. Open the read the Wikipedia data JSON file.\n",
    "    with open(wiki_file, mode='r') as file:\n",
    "        wiki_movies_json = json.load(file)\n",
    "    \n",
    "    # Remove TV shows\n",
    "    wiki_movies_json = [wiki_movies_json[i]\\\n",
    "                        for i in range(len(wiki_movies_json))\\\n",
    "                        if 'No. of episodes' not in wiki_movies_json[i]]\n",
    "    \n",
    "    # Iterate through clean movie function to tidy columns\n",
    "    wiki_movies_json = [clean_movie(wiki_movies_json[i]) for i in range(len(wiki_movies_json))]\n",
    "    \n",
    "    # Create dataframe\n",
    "    wiki_movies_df = pd.DataFrame(wiki_movies_json)\n",
    "    \n",
    "    # Extract all IMDB IDs from valid URls and remove records that do not contain them\n",
    "    try:\n",
    "        wiki_movies_df.dropna(subset=['imdb_link'], inplace=True)\n",
    "        wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "        wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "    except:\n",
    "        print('IMDB extraction failed.')\n",
    "    \n",
    "    columns_to_drop = [column\\\n",
    "                         for column in wiki_movies_df.columns\\\n",
    "                         if wiki_movies_df[column].count() == 0]   \n",
    "        \n",
    "    wiki_movies_df.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "    #Regex strings for currency patterns                                   \n",
    "    form_one = r\"\\$\\s*\\d{1,3}\\.?\\d*\\s*[mb]illi?on\"                                       \n",
    "    form_two = r\"\\$\\s*\\d+[,\\.]\\d{3}\"\n",
    "                                       \n",
    "    box_office = wiki_movies_df['Box office'].dropna()\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)                                       \n",
    "                                       \n",
    "    wiki_movies_df['box_office'] = box_office.str.\\\n",
    "                                    extract(f\"({form_one}|{form_two})\",\\\n",
    "                                            flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "    \n",
    "    # BUDGET\n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "    budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    \n",
    "    # Omit wikipedia citation markers using square brackets\n",
    "    budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "\n",
    "    # Remove any hyphens and defer to smaller end of range\n",
    "    budget = budget.str.replace(r'\\$.*[-—–](?![a-z])' , '$', regex=True)\n",
    "\n",
    "    contains_form_one = budget.str.contains(pat=form_one, flags=re.IGNORECASE, na=False)\n",
    "    contains_form_two = budget.str.contains(pat=form_two, flags=re.IGNORECASE, na=False)\n",
    "    \n",
    "    wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
    "    \n",
    "    # fix release date col\n",
    "    release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "    # match string one: Month Name, 1-2 digits, 4 digit year\n",
    "    date_pat_1 = r\"\\w*\\s\\d{1,2},\\s\\d{4}\"\n",
    "    matches_pat_1 = release_date.str.contains(date_pat_1, flags=re.IGNORECASE, na=False)\n",
    "\n",
    "    # pattern 2: yyyy-dd-mm\n",
    "    date_pat_2 = r\"\\d{4}[-—–]\\d{2}[-—–]\\d{2}\"\n",
    "    matches_pat_2 = release_date.str.contains(date_pat_2, flags=re.IGNORECASE, na=False)\n",
    "\n",
    "    # pattern 3: (optional day), month name, year\n",
    "    date_pat_3 = r\"\\d{0,2}\\s*\\w{3,10}\\s\\d{4}\"\n",
    "    matches_pat_3 = release_date.str.contains(date_pat_3, flags=re.IGNORECASE, na=False)\n",
    "\n",
    "    # pattern 4: four digit year only\n",
    "    date_pat_4 = r\"\\d{4}\"\n",
    "    matches_pat_4 = release_date.str.contains(date_pat_4, flags=re.IGNORECASE, na=False)\n",
    "\n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(\n",
    "        release_date.str.extract(f'({date_pat_1}|{date_pat_2}|{date_pat_3}|{date_pat_4})')[0],\n",
    "        infer_datetime_format=True,\n",
    "        errors='coerce')\n",
    "    \n",
    "    wiki_movies_df.drop('Release date', axis=1, inplace=True)    \n",
    "    \n",
    "    # fix runtime\n",
    "    \n",
    "    # 5. Return the three DataFrames\n",
    "    return wiki_movies_df, kaggle_metadata, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Map to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 17. Create the path to your file directory and variables for the three files.\n",
    "file_dir = './data'\n",
    "# Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia-movies.json'\n",
    "# Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\espoe\\anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:152: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "# 18. Set the three variables equal to the function created in D1.\n",
    "wiki_file, kaggle_file, ratings_file = import_source_files(wiki_file=wiki_file, \n",
    "                                                           kaggle_file=kaggle_file, \n",
    "                                                           ratings_file=ratings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7049"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 19. Set the wiki_movies_df equal to the wiki_file variable. \n",
    "wiki_movies_df = wiki_file\n",
    "wiki_movies_df[\"box_office\"].isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                  7049\n",
       "year                 7049\n",
       "imdb_link            7049\n",
       "title                7044\n",
       "Screenplay by        2307\n",
       "                     ... \n",
       "Television series       1\n",
       "imdb_id              7049\n",
       "box_office           5459\n",
       "budget               4705\n",
       "release_date         6236\n",
       "Length: 90, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20. Check that the wiki_movies_df DataFrame looks like this. \n",
    "wiki_movies_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'year',\n",
       " 'imdb_link',\n",
       " 'title',\n",
       " 'Screenplay by',\n",
       " 'Story by',\n",
       " 'Based on',\n",
       " 'Starring',\n",
       " 'Narrated by',\n",
       " 'Music by',\n",
       " 'Cinematography',\n",
       " 'Productioncompany ',\n",
       " 'Running time',\n",
       " 'Country',\n",
       " 'Language',\n",
       " 'Director(s)',\n",
       " 'Distributor',\n",
       " 'Editor(s)',\n",
       " 'Producer(s)',\n",
       " 'Writer(s)',\n",
       " 'Genre',\n",
       " 'Theme music composer',\n",
       " 'Original language(s)',\n",
       " 'Production company(s)',\n",
       " 'Original network',\n",
       " 'Productioncompanies ',\n",
       " 'Executive producer(s)',\n",
       " 'Production location(s)',\n",
       " 'Picture format',\n",
       " 'Audio format',\n",
       " 'Voices of',\n",
       " 'Followed by',\n",
       " 'Composer(s)',\n",
       " 'Created by',\n",
       " 'Preceded by',\n",
       " 'Author',\n",
       " 'Publisher',\n",
       " 'Publication date',\n",
       " 'Media type',\n",
       " 'Pages',\n",
       " 'ISBN',\n",
       " 'OCLC',\n",
       " 'LC Class',\n",
       " 'Cover artist',\n",
       " 'Series',\n",
       " 'Set in',\n",
       " 'Adaptation by',\n",
       " 'Suggested by',\n",
       " 'alt_titles',\n",
       " 'Released',\n",
       " 'Recorded',\n",
       " 'Venue',\n",
       " 'Label',\n",
       " 'Area',\n",
       " 'Coordinates',\n",
       " 'Status',\n",
       " 'Opening date',\n",
       " 'Closing date',\n",
       " 'Replaced',\n",
       " 'Replaced by',\n",
       " 'Name',\n",
       " 'Attraction type',\n",
       " 'Music',\n",
       " 'Duration',\n",
       " 'Also known as',\n",
       " 'Animation by',\n",
       " 'Color process',\n",
       " 'Characters',\n",
       " 'Date premiered',\n",
       " 'Place premiered',\n",
       " 'Setting',\n",
       " 'Original language',\n",
       " 'Subject',\n",
       " 'Text',\n",
       " 'Original title',\n",
       " 'Nationality',\n",
       " 'Portrayed by',\n",
       " 'Alias',\n",
       " 'Species',\n",
       " 'Gender',\n",
       " 'Family',\n",
       " 'Alma mater',\n",
       " 'Film(s)',\n",
       " 'Screen story by',\n",
       " 'Original work',\n",
       " 'Television series',\n",
       " 'imdb_id',\n",
       " 'box_office',\n",
       " 'budget',\n",
       " 'release_date']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21. Check that wiki_movies_df DataFrame columns are correct. \n",
    "wiki_movies_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print([column\\\n",
    "#        for column in wiki_movies_df.columns\\\n",
    "#        if wiki_movies_df[column].count()/len(wiki_movies_df) < .01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Publication date       4\n",
       "Released               4\n",
       "Opening date           1\n",
       "Closing date           1\n",
       "Date premiered         1\n",
       "Place premiered        1\n",
       "release_date        6236\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## exploratory, check out release date\n",
    "release_date_column = [column\\\n",
    "                       for column in wiki_movies_df.columns\\\n",
    "                       if 'date' in column.lower()\\\n",
    "                           or 'release' in column.lower()\\\n",
    "                           or 'premiere' in column.lower()]\n",
    "\n",
    "wiki_movies_df[release_date_column].count()\n",
    "\n",
    "# wiki_movies_df[['Date premiered', 'Date ']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "# release_date.head(50)\n",
    "\n",
    "# # match string one: Month Name, 1-2 digits, 4 digit year\n",
    "date_pat_1 = r\"\\w*\\s\\d{1,2},\\s\\d{4}\"\n",
    "matches_pat_1 = release_date.str.contains(date_pat_1, flags=re.IGNORECASE, na=False)\n",
    "# matches_pat_1.head(50)\n",
    "# release_date[~matches_pat_1].sample(50)\n",
    "\n",
    "# # pattern 2: yyyy-dd-mm\n",
    "date_pat_2 = r\"\\d{4}[-—–]\\d{2}[-—–]\\d{2}\"\n",
    "matches_pat_2 = release_date.str.contains(date_pat_2, flags=re.IGNORECASE, na=False)\n",
    "# release_date[matches_pat_2].sample(50)\n",
    "release_date[~matches_pat_1 & ~matches_pat_2].sample(50)\n",
    "\n",
    "# pattern 3: month name, year\n",
    "date_pat_3 = r\"\\d{0,2}\\s*\\w{3,10}\\s\\d{4}\"\n",
    "matches_pat_3 = release_date.str.contains(date_pat_3, flags=re.IGNORECASE, na=False)\n",
    "# release_date[~matches_pat_1 & ~matches_pat_2 & ~matches_pat_3].sample(50)\n",
    "\n",
    "# pattern 4: four letter year\n",
    "date_pat_4 = r\"\\d{4}\"\n",
    "matches_pat_4 = release_date.str.contains(date_pat_4, flags=re.IGNORECASE, na=False)\n",
    "release_date[~matches_pat_1 & ~matches_pat_2 & ~matches_pat_3 & ~matches_pat_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df['release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
